{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dissertation saved.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aabdelmak/Dissertation/blob/master/Dissertation_saved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1FEOyPdqhuZ"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.cbook as cbook\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('pdf', 'png')\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import sklearn as sk\n",
        "from sklearn import svm, neighbors, preprocessing\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from statsmodels.graphics import tsaplots\n",
        "import statsmodels.api as sm\n",
        "from pylab import rcParams\n",
        "\n",
        "from subprocess import check_output\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "import time #helper libraries\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import newaxis\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import datetime as dt\n",
        "import bs4 as bs\n",
        "import pickle\n",
        "import requests\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n",
        "import pandas_datareader.data as pdr\n",
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "yf.pdr_override\n",
        "\n",
        "import prettytable as pt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nxiG--gw3MV"
      },
      "source": [
        "def get_data_from_yahoo():\n",
        "\n",
        "    tickers = [\"^GSPC\", \"^DJI\", \"^NYA\", \"^GDAXI\", \"^IXIC\",\n",
        "               \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\", \"^VIX\"]\n",
        "            \n",
        "    if not os.path.exists(\"index_dfs\"):\n",
        "        os.makedirs(\"index_dfs\")\n",
        "    start = dt.datetime(1991, 12, 15)\n",
        "    end = dt.datetime.now()\n",
        "    \n",
        "    for ticker in tickers:\n",
        "        print(ticker)\n",
        "        \n",
        "        if not os.path.exists(\"index_dfs/{}.csv\".format(ticker)):\n",
        "            time.sleep(3)\n",
        "            df = pdr.get_data_yahoo(ticker, start, end)\n",
        "            df.reset_index(inplace=True)\n",
        "            df.set_index(\"Date\", inplace=True)\n",
        "            df.to_csv(\"index_dfs/{}.csv\".format(ticker))\n",
        "            time.sleep(3)\n",
        "        else:\n",
        "            print(\"Already have {}\".format(ticker))\n",
        "            \n",
        "get_data_from_yahoo()\n",
        "\n",
        "def compile_data():\n",
        "    tickers = [\"^GSPC\", \"^DJI\", \"^NYA\", \"^GDAXI\", \"^IXIC\",\n",
        "               \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\", \"^VIX\"]\n",
        "        \n",
        "    main_df = pd.DataFrame()\n",
        "    for count,ticker in enumerate(tickers):\n",
        "        df = pd.read_csv(\"index_dfs/{}.csv\".format(ticker))\n",
        "        df.set_index(\"Date\", inplace = True)\n",
        "        \n",
        "        df.rename(columns = {\"Adj Close\": \"{} Adj Close\".format(ticker),\n",
        "                            \"Open\": \"{} Open\".format(ticker),\n",
        "                            \"High\": \"{} High\".format(ticker),\n",
        "                            \"Low\" : \"{} Low\".format(ticker),\n",
        "                            \"Volume\":\"{} Volume\".format(ticker)},\n",
        "                   inplace = True)\n",
        "        df.drop(\"Close\", axis = 1, inplace = True)\n",
        "        \n",
        "        if main_df.empty:\n",
        "            main_df = df\n",
        "        else:\n",
        "            main_df = main_df.join(df, how = \"outer\") \n",
        "        if count % 10 == 0:\n",
        "            print(count)\n",
        "        print(main_df.head())\n",
        "        main_df.to_csv(\"Indices.csv\")\n",
        "compile_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abGfJ4GPQyB"
      },
      "source": [
        "After compiling the csv file with the desired tickers, we select the columns that we wish to load into a dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d0BHdEayoip"
      },
      "source": [
        "#pre-define dates and tickers \n",
        "tickers = [\"^GSPC\", \"^DJI\", \"^NYA\", \"^GDAXI\", \"^IXIC\",\n",
        "           \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\", \"^VIX\"]\n",
        "start_date = \"1991-12-15\"\n",
        "end_date = \"2020-09-15\"\n",
        "dates = pd.date_range(start_date, end_date)\n",
        "#select columns from data\n",
        "def select_columns_from_data(data, ticker_list, column_names): \n",
        "    df = pd.DataFrame(index = dates)\n",
        "    for ticker in ticker_list:\n",
        "      for column_name in column_names:\n",
        "        df_temp = pd.read_csv(\"/content/Indices.csv\", index_col = \"Date\",\n",
        "                             parse_dates = True, usecols =\\\n",
        "                              [\"Date\", \"{} {}\".format(ticker, column_name)], \n",
        "                              na_values = [\"nan\"])\n",
        "        df = df.join(df_temp)\n",
        "        if ticker == \"^GSPC\": # drop dates SPY did not trade\n",
        "          df = df.dropna(subset=[\"^GSPC {}\".format(column_name)])\n",
        "            \n",
        "    return df    \n",
        "    \n",
        "price_data = select_columns_from_data(pd.read_csv(\"Indices.csv\"), tickers, \n",
        "                         [\"Adj Close\", \"High\", \"Low\", \"Open\"])\n",
        "volume_data = select_columns_from_data(pd.read_csv(\"Indices.csv\"), tickers,\n",
        "                                       [\"Volume\"])\n",
        "        \n",
        "#Fill NA values\n",
        "price_data.fillna(method = \"ffill\", inplace = True)\n",
        "price_data.fillna(method = \"bfill\", inplace = True)\n",
        "volume_data.fillna(method = \"ffill\", inplace = True)\n",
        "volume_data.fillna(method = \"bfill\", inplace = True)\n",
        "\n",
        "#price_data[:252] #252\n",
        "#price_data[253:500] #247\n",
        "price_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-yxzqTzAx6J"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC4skOeaLPRV"
      },
      "source": [
        "\n",
        "#Plot data        \n",
        "font = {'family': 'Serif',\n",
        "        'color':  'black',\n",
        "        'weight': 'normal',\n",
        "        'size': 40,\n",
        "        }\n",
        "\n",
        "def plot_data(df, savefig, label):\n",
        "    \"\"\"Plot stock prices\"\"\"\n",
        "    ax = df.plot(grid = True, figsize = (20, 10), cmap = \"Spectral\")\n",
        "    datemin = np.datetime64(df.index.values[22], 'Y')\n",
        "    datemax = np.datetime64(df.index.values[-1], 'Y') + np.timedelta64(1, 'Y') \n",
        "    ax.set_xlim(datemin, datemax)\n",
        "    ax.set_xlabel(\"Date\", fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    plt.title(\"{}\".format(label),fontdict = font )\n",
        "    \n",
        "\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=52))\n",
        "# set formatter\n",
        "\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "        matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.rc(\"legend\", fontsize=20)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(fontsize = 20)\n",
        "    plt.savefig(savefig)\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "#define closing_prices for plot\n",
        "def get_closing_data_for_plot(tickers, from_data, column):\n",
        "  closing_data = pd.DataFrame(index = from_data.index)\n",
        "  for ticker in tickers:\n",
        "    tmp = from_data.pop(\"{} {}\".format(ticker, column))\n",
        "    closing_data= closing_data.join(tmp)\n",
        "  return closing_data\n",
        "\n",
        "closing_data = get_closing_data_for_plot(tickers, price_data,\"Adj Close\")\n",
        "\n",
        "closing_data\n",
        "vix_closing_data = pd.DataFrame(closing_data.pop(\"^VIX Adj Close\") ,\n",
        "                                index = closing_data.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAitSU04hoX3"
      },
      "source": [
        "closing_data = closing_data.join(vix_closing_data[\"^VIX Adj Close\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-itoDq-nDnd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbZEcTofhBx"
      },
      "source": [
        "#scaler = MinMaxScaler(feature_range = (0,1))\n",
        "#scaled_price_data = scaler.fit_transform(price_data) \n",
        "#scaled_price_data= pd.DataFrame(scaled_price_data, index = price_data.index, columns = price_data.columns)\n",
        "\n",
        "#names = [\"High\", \"Low\",\"Open\"]\n",
        "#counter = 0\n",
        "\n",
        "#scaled_price_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvRTsIMvAyQL"
      },
      "source": [
        "plot_data(closing_data, \"Adj Close.pdf\",\"Adj Closing Prices for Selected Stock Indices\")\n",
        "scaled_data = closing_data.copy()\n",
        "for column in scaled_data:\n",
        "  scaled_data[column]= scaled_data[column]/max(scaled_data[column])\n",
        "for ticker in tickers: \n",
        "  scaled_data =scaled_data.rename(columns = {\"{} Adj Close\".format(ticker): \"{} Scaled Close\".format(ticker) })\n",
        "scaled_data\n",
        "\n",
        "\n",
        "\n",
        "def plot_data(df, savefig, label):\n",
        "    \"\"\"Plot stock prices\"\"\"\n",
        "    ax = df.plot(grid = True, figsize = (20, 10), cmap = \"Spectral\")\n",
        "    datemin = np.datetime64(df.index.values[22], 'Y')\n",
        "    datemax = np.datetime64(df.index.values[-1], 'Y') + np.timedelta64(1, 'Y') \n",
        "    ax.set_xlim(datemin, datemax)\n",
        "    ax.set_xlabel(\"Date\", fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    plt.title(\"{}\".format(label),fontdict = font )\n",
        "    \n",
        "\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=54))\n",
        "# set formatter\n",
        "\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.rc(\"legend\", fontsize=20)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(fontsize = 20)\n",
        "    plt.savefig(savefig)\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_data(scaled_data, \"Scaled Close.pdf\", \"Scaled Closing Prices for Selected Stock Indices\")\n",
        "\n",
        "\n",
        "def plot_autocorrelation(df, savefig, tickerlist, datacolumn):\n",
        "  fig = plt.figure()\n",
        "  fig.set_figwidth(20)\n",
        "  fig.set_figheight(10)\n",
        "  for ticker in tickerlist:\n",
        "    ax = autocorrelation_plot(df[\"{} {}\".format(ticker, datacolumn)], label = \"{}\".format(ticker))\n",
        "  ax.set_xlabel(\"Lags\", fontsize = 30, fontdict = font)\n",
        "  \n",
        "  ax.set_ylabel(\"Autocorrelation\", fontsize = 30, fontdict = font)\n",
        "  \n",
        "  plt.title(\"Autocorrelation Plot of Selected Indices\",fontdict = font)\n",
        "  plt.legend(loc = \"upper right\")\n",
        "  plt.savefig(savefig)\n",
        "\n",
        "#plot_autocorrelation(df = closing_data,\n",
        " #                    savefig = \"Autocorrelation Plot of Closing Data.pdf\",\n",
        "  #                   tickerlist = tickers, datacolumn = \"Adj Close\")\n",
        "\n",
        "def plot_scatter_matrix(df, savefig, tickerlist, datacolumn):\n",
        "    plot_frame = pd.concat([df[\"{} {}\".format(tickerlist[0], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[1], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[2], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[3], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[4], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[5], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[6], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[7], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[8], datacolumn)],\n",
        "                            df[\"{} {}\".format(tickerlist[9], datacolumn)]], axis = 1)\n",
        "    plt.savefig(\"savefig1.pdf\")\n",
        "    scatter_matrix(plot_frame, figsize = (20,20), diagonal = \"kde\")\n",
        "    plt.savefig(savefig)\n",
        "    plt.show()\n",
        "plot_autocorrelation(closing_data, \"Autocorrelation Closing data.pdf\",tickers, \"Adj Close\")\n",
        "#plot_frame.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHW9BsresXOx"
      },
      "source": [
        "#plot_scatter_matrix(df = closing_data,\n",
        " #                   savefig = \"Scatter Plot of Closing Data.pdf\",\n",
        "  #                  tickerlist = tickers, datacolumn = \"Adj Close\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2bAlZ-sLYtb"
      },
      "source": [
        "def plot_data(df, savefig, label):\n",
        "    \"\"\"Plot stock prices\"\"\"\n",
        "    ax = df.plot(grid = True, figsize = (20, 10))\n",
        "    datemin = np.datetime64(df.index.values[22], 'Y')\n",
        "    datemax = np.datetime64(df.index.values[-1], 'Y') + np.timedelta64(1, 'Y') \n",
        "    ax.set_xlim(datemin, datemax)\n",
        "    ax.set_xlabel(\"date\", fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"price\", fontsize = 30, fontdict = font)\n",
        "    plt.title(\"{}\".format(label),fontdict = font )\n",
        "    \n",
        "\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=25))\n",
        "# set formatter\n",
        "\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "        matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.rc(\"legend\", fontsize=20)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(fontsize = 20)\n",
        "    plt.savefig(savefig)\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvXJpFcFLkxb"
      },
      "source": [
        "#plot_data(vix_closing_data,\"VIX Adj Close.pdf\", \"Adj Closing Prices for Volatility Index (VIX)\")\n",
        "\n",
        "#price_data, volume_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_qKy6UCy0PB"
      },
      "source": [
        "def compute_daily_returns(df, tickerlist):\n",
        "    newdf = pd.DataFrame(index = df.index)\n",
        "    for column in df:\n",
        "      df_temp = (df[column]/df[column].shift())-1\n",
        "      newdf = newdf.join(df_temp)\n",
        "      newdf = newdf.dropna()\n",
        "    for ticker in tickers:\n",
        "      newdf = newdf.rename(columns = {\"{} Adj Close\".format(ticker) : \"{} Daily Return\".format(ticker)})\n",
        "    returns_data = df.copy()\n",
        "    returns_data = returns_data.join(newdf)\n",
        "    return returns_data\n",
        "\n",
        "def compute_cumulative_returns(df, tickers, final_dataset):\n",
        "  newdf = pd.DataFrame(index = df.index)\n",
        "  newdf = (df[:]/df.iloc[0].values)-1\n",
        "  newdf = newdf.dropna()\n",
        "  for ticker in tickers:\n",
        "    newdf = newdf.rename(columns = {\"{} Adj Close\".format(ticker) : \"{} Cumulative Returns\".format(ticker)})\n",
        "  final_dataset = final_dataset.join(newdf)\n",
        "  return final_dataset\n",
        "\n",
        "\n",
        "tickers = [\"^VIX\",\"^GSPC\", \"^DJI\", \"^NYA\", \"^GDAXI\", \"^IXIC\",\n",
        "           \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\"]\n",
        "\n",
        "def Kurtosis(data, tickerlist):\n",
        "    fig, ((ax0, ax1), (ax2, ax3), (ax4, ax5), (ax6, ax7), (ax8, ax9)) = plt.subplots(\n",
        "        nrows=5, ncols=2, figsize = (20, 16))\n",
        "    n_bins = 50\n",
        "    k0= data[\"{} Daily Return\".format(tickerlist[0])].kurtosis()   \n",
        "    ax0.hist(data[\"{} Daily Return\".format(tickerlist[0])], n_bins, density=True, \n",
        "             histtype='bar', label= str(tickerlist[0]))\n",
        "    ax0.legend(prop={'size': 20})\n",
        "    ax0.set_title('GSPC Daily Returns Histogram, Kurtosis: {0:.2f}'.format(k0), fontsize = 20)\n",
        "    k1= data[\"{} Daily Return\".format(tickerlist[1])].kurtosis()\n",
        "    ax1.hist(data[\"{} Daily Return\".format(tickerlist[1])], n_bins, density=True, \n",
        "             histtype='bar', stacked=True, label= str(tickerlist[1]))\n",
        "    ax1.legend(prop={'size': 20})\n",
        "    ax1.set_title('DJI Daily Returns Histogram, Kurtosis: {0:.2f}'.format(k1), fontsize = 20)\n",
        "    k2= data[\"{} Daily Return\".format(tickerlist[2])].kurtosis()\n",
        "    ax2.hist(data[\"{} Daily Return\".format(tickerlist[2])], n_bins, histtype='bar', \n",
        "             stacked=True, label = str(tickerlist[2]))\n",
        "    ax2.legend(prop={'size': 20})\n",
        "    ax2.set_title('NYA Daily Return Histogram, Kurtosis: {0:.2f})'.format(k2),fontsize = 20)\n",
        "    k3= data[\"{} Daily Return\".format(tickerlist[3])].kurtosis()\n",
        "    ax3.hist(data[\"{} Daily Return\".format(tickerlist[3])], n_bins, density=True, \n",
        "             histtype='bar', stacked=True ,label= str(tickerlist[3]))\n",
        "    ax3.legend(prop={'size': 20})\n",
        "    ax3.set_title('GDAXI Daily Return Histogram, Kurtosis: {0:.2f}'.format(k3), fontsize = 20)\n",
        "    k4= data[\"{} Daily Return\".format(tickerlist[4])].kurtosis()\n",
        "    ax4.hist(data[\"{} Daily Return\".format(tickerlist[4])], n_bins, density=True,\n",
        "             histtype='bar', stacked=True, label= str(tickerlist[4]))\n",
        "    ax4.legend(prop={'size': 20})\n",
        "    ax4.set_title('IXIC Daily Return Histogram, Kurtosis: {0:.2f}'.format(k4), fontsize = 20)\n",
        "    k5= data[\"{} Daily Return\".format(tickerlist[5])].kurtosis()\n",
        "    ax5.hist(data[\"{} Daily Return\".format(tickerlist[5])], n_bins, histtype = \"bar\", \n",
        "             stacked=True, label= str(tickerlist[5]))\n",
        "    ax5.legend(prop={'size': 20})\n",
        "    ax5.set_title('FCHI Daily Return Histogram, Kurtosis: {0:.2f}'.format(k5), fontsize = 20)\n",
        "    k6= data[\"{} Daily Return\".format(tickerlist[6])].kurtosis()\n",
        "    ax6.hist(data[\"{} Daily Return\".format(tickerlist[6])], n_bins, density=True,\n",
        "             histtype='bar', label= str(tickerlist[6]))\n",
        "    ax6.legend(prop={'size': 20})\n",
        "    ax6.set_title('HSI Daily Return Histogram, Kurtosis: {0:.2f}'.format(k6), fontsize = 20)\n",
        "    k7= data[\"{} Daily Return\".format(tickerlist[7])].kurtosis()\n",
        "    ax7.hist(data[\"{} Daily Return\".format(tickerlist[7])], n_bins, density=True,\n",
        "             histtype='bar', stacked=True, label= str(tickerlist[7]))\n",
        "    ax7.legend(prop={'size': 20})\n",
        "    ax7.set_title('N225 Daily Return Histogram, Kurtosis: {0:.2f}'.format(k7), fontsize = 20)\n",
        "    k8 = data[\"{} Daily Return\".format(tickerlist[8])].kurtosis()\n",
        "    ax8.hist(data[\"{} Daily Return\".format(tickerlist[8])], n_bins, histtype='bar', \n",
        "             stacked=True, label= str(tickerlist[8]))\n",
        "    ax8.legend(prop={'size': 20})\n",
        "    ax8.set_title('RUT Daily Return Histogram, Kurtosis: {0:.2f}'.format(k8), fontsize = 20)\n",
        "\n",
        "    k9 = data[\"{} Daily Return\".format(tickerlist[9])].kurtosis()\n",
        "    ax9.hist(data[\"{} Daily Return\".format(tickerlist[9])], n_bins, histtype='bar', \n",
        "             stacked=True, label= str(tickerlist[9]))\n",
        "    ax9.legend(prop={'size': 20})\n",
        "    ax9.set_title('RUT Daily Return Histogram, Kurtosis: {0:.2f}'.format(k9), fontsize = 20)\n",
        "\n",
        "    #Plot Histogram\n",
        "    num_bins = 50\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(\"Return Histograms.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "    #Compute kurtosis\n",
        "      \n",
        "\n",
        "#########################################################\n",
        "tickers = [\"^VIX\",\"^GSPC\", \"^DJI\", \"^NYA\", \"^GDAXI\", \"^IXIC\",\n",
        "           \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\"]\n",
        "\n",
        "returns_data = compute_daily_returns(closing_data, tickers)\n",
        "returns_data = compute_cumulative_returns(closing_data, tickers, returns_data)\n",
        "returns_data\n",
        "\n",
        "#######################################################\n",
        "def plot_return_data(df, savefig, label, title):\n",
        "    \"\"\"Plot stock prices\"\"\"\n",
        "    ax = df.plot(grid = True, figsize = (20, 10), cmap = \"Spectral\")\n",
        "    datemin = np.datetime64(df.index.values[22], 'Y')\n",
        "    datemax = np.datetime64(df.index.values[-1], 'Y') + np.timedelta64(1, 'Y') \n",
        "    ax.set_xlim(datemin, datemax)\n",
        "    ax.set_xlabel(\"Date\", fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Return Value\", fontsize = 30, fontdict = font)\n",
        "    plt.title(\"{}\".format(title),fontdict = font )\n",
        "    \n",
        "\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval= 54))\n",
        "# set formatter\n",
        "\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.rc(\"legend\", fontsize=20)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\",fontsize = 20)\n",
        "    plt.savefig(savefig)\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "plot_return_data(returns_data.iloc[:,10:-11], \"Stock Daily Returns.pdf\", \n",
        "                 label = tickers, \n",
        "                 title = \"Plot of Daily Returns for Selected Stock Indices\"),\\\n",
        "                 plot_return_data(returns_data.iloc[:,-10:-2], \n",
        "                                  \"Stock Cumulative Returns.pdf\", \n",
        "                                  label = tickers, title =\\\n",
        "                                  \"Plot of Cumulative Returns for Selected Stock Indices\")\n",
        "\n",
        "plot_autocorrelation(returns_data, \"Autocorrelation of Daily Returns.pdf\", tickers, \"Daily Return\")\n",
        "\n",
        "Kurtosis(returns_data, tickers) \n",
        "returns_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "280uUhsj6hMY"
      },
      "source": [
        "plot_scatter_matrix(returns_data, \"Scatter Matrix of Daily Returns.pdf\", tickers, \"Daily Return\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI3lqdsyTg26"
      },
      "source": [
        "#Plot data        \n",
        "font = {'family': 'serif',\n",
        "        'color':  'black',\n",
        "        'weight': 'normal',\n",
        "        'size': 40,\n",
        "        }\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#DEFINE ROLLING STATISTICS FUNCTIONS:\n",
        "\n",
        "def get_MA(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_{}d_MA\".format(str(window))] = pd.DataFrame.rolling(\n",
        "        values, window).mean() #rolling mean\n",
        "\n",
        "def get_rolling_std(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_{}d_RSTD\".format(str(window))] = pd.DataFrame.rolling(\n",
        "        values, window).std() #rolling std\n",
        "\n",
        "def get_bollinger_bands(windows):#bbands\n",
        "    for window in windows:\n",
        "      returns_data[\"upper_band_{}d\".format(window)] = returns_data[\"^GSPC_{}d_MA\".format(window)] + 20 * returns_data[\"^GSPC_{}d_RSTD\".format(window)]\n",
        "      returns_data[\"lower_band_{}d\".format(window)] = returns_data[\"^GSPC_{}d_MA\".format(window)] - 20 * returns_data[\"^GSPC_{}d_RSTD\".format(window)]\n",
        "\n",
        "def get_EMA(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_{}d_EMA\".format(\n",
        "        str(window))] = returns_data[\"^GSPC Adj Close\"].ewm(\n",
        "            span = window, adjust = False).mean() # exponential moving average\n",
        "\n",
        "def get_max(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_{}d_max\".format(str(window))] =\\\n",
        "     pd.DataFrame.rolling(values, window).max() #rolling mean\n",
        "\n",
        "def get_min(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_{}d_min\".format(str(window))] =\\\n",
        "     pd.DataFrame.rolling(values, window).min() #rolling mean\n",
        "\n",
        "def get_OSCP(values):\n",
        "  returns_data[\"^GSPC_OSCP\"] =\\\n",
        "   (pd.DataFrame.rolling(values, 5).mean() -\\\n",
        "    pd.DataFrame.rolling(values, 10).mean())/pd.DataFrame.rolling(values, \n",
        "                                                                  5).mean()\n",
        "def get_MACD(values):\n",
        "  returns_data[\"^GSPC_MACD\"] =\\\n",
        "  values.ewm(span = 12, adjust = False).mean() -\\\n",
        "  values.ewm(span = 26, adjust = False).mean()\n",
        "\n",
        "def get_signal_line(values):\n",
        "    returns_data[\"^GSPC signal line\"] = values.ewm(\n",
        "        span = 9, adjust = False).mean() # exponential moving average\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#COMPUTE ROLLING STATISTICS#\n",
        "\n",
        "get_MA(returns_data[\"^GSPC Adj Close\"],[3, 5, 10, 21]) \n",
        "\n",
        "#MA5, MA10, MA60, MA120 \n",
        "#1 week, 2 weeks, monthly, quarterly, half-year\n",
        " \n",
        "get_rolling_std(returns_data[\"^GSPC Adj Close\"], [3, 5, 10, 21])\n",
        "\n",
        "get_bollinger_bands([3, 5, 10, 21])\n",
        "\n",
        "get_EMA(returns_data[\"^GSPC Adj Close\"], [3, 5, 10, 21])\n",
        "\n",
        "get_max(returns_data[\"^GSPC Adj Close\"], [3, 5, 10, 21])\n",
        "#\n",
        "get_min(returns_data[\"^GSPC Adj Close\"], [3, 5, 10, 21])\n",
        "\n",
        "get_MACD(returns_data[\"^GSPC Adj Close\"])\n",
        "\n",
        "get_signal_line(returns_data[\"^GSPC_MACD\"])\n",
        "\n",
        "################################################################################\n",
        "\n",
        "#PLOT ROLLING STATISTICS#\n",
        "\n",
        "#BOLLINGER BANDS\n",
        "def plot_bbands(bbands, label):\n",
        "    ax = returns_data[\"^GSPC Adj Close\"].plot(\n",
        "        title = \"GSPC Monthly Bollinger Band Plot\", label = label,\n",
        "        figsize = (20, 10), color = \"black\")\n",
        "    plt.title(\"GSPC Monthly Bollinger Band Plot\",fontdict = font)\n",
        "\n",
        "    bbands[0].plot(label =  \"upper band\", ax = ax, color = \"orchid\")\n",
        "    bbands[1].plot(label = \"lower band\", ax = ax, color = \"cornflowerblue\")\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 40, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 40, fontdict = font)\n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=54)) # set formatter\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) \n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') + np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax) \n",
        "    plt.xticks(rotation = 0)\n",
        "\n",
        "    plt.savefig(\"Monthly Bollinger Bands.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "plot_bbands(bbands = [returns_data[\"upper_band_10d\"] ,returns_data[\"lower_band_10d\"]], label = \"^GSPC\")\n",
        "\n",
        "#MOVING AVERAGE  \n",
        "\n",
        "def plot_MA(rm, label):\n",
        "    ax = returns_data[\"^GSPC Adj Close\"].plot(\n",
        "        title = \"GSPC Monthly Moving Average\", label = label,\n",
        "         figsize = (20, 10), color = \"black\")\n",
        "    plt.title(\"GSPC Monthly Moving Average\", fontdict = font)\n",
        "    rm.plot(label = \"Moving Average\", ax = ax,\n",
        "            color = \"cornflowerblue\", alpha = 1) #p\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "        matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=54))\n",
        "# set formatter\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
        "# set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') +\\\n",
        "     np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax) \n",
        "    plt.xticks(rotation = 0)\n",
        "\n",
        "    plt.savefig(\"Monthly Moving Average.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_MA(rm = returns_data[\"^GSPC_21d_MA\"], label = \"^GSPC\")\n",
        "\n",
        "#EXPONENTIAL MOVING AVERAGE PLOT\n",
        "def plot_EMA(rm, label):\n",
        "    ax = returns_data[\"^GSPC Adj Close\"].plot(\n",
        "        title = \"GSPC Exponentially Moving Average\", label = label,\n",
        "        figsize = (20, 10), color = \"black\")\n",
        "    plt.title(\"GSPC Monthly Exponentially Moving Average\", fontdict = font)\n",
        "    rm.plot(label = \"Exponential Moving Average\", ax = ax,\n",
        "            color = \"cornflowerblue\", alpha = 1) #p\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    \n",
        "    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 54)) \n",
        "    # set formatter\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) \n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') +\\\n",
        "     np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax) \n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.savefig(\"Monthly Exponential Moving Average.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "plot_EMA(rm = returns_data[\"^GSPC_21d_EMA\"], label = \"^GSPC\")\n",
        "\n",
        "#ROLLING MAX CLOSE\n",
        "\n",
        "def plot_max(rm, label):\n",
        "    ax = returns_data[\"^GSPC Adj Close\"].plot(\n",
        "        title = \"GSPC Monthly Rolling Max \", label = label,\n",
        "        figsize = (20, 10), color = \"black\")\n",
        "    plt.title(\"GSPC Monthly Rolling Max\", fontdict = font)\n",
        "    rm.plot(label = \"Monthly Rolling Max\", ax = ax,\n",
        "            color = \"#9a0200\", alpha = 1) #p\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    \n",
        "    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 54)) \n",
        "    # set formatter\n",
        "    ax.get_yaxis().set_major_formatter(\n",
        "    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) \n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') +\\\n",
        "     np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax)\n",
        "    plt.xticks(rotation = 0) \n",
        "\n",
        "    plt.savefig(\"Monthly Rolling Max.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "plot_max(rm = returns_data[\"^GSPC_21d_max\"], label = \"^GSPC\")\n",
        "\n",
        "#OSCP (MOMENTUM INDICATOR) \n",
        "\n",
        "\n",
        "#OSCP (MOMENTUM INDICATOR) \n",
        "\n",
        "def plot_MACD(rm,label):\n",
        "    ax = returns_data[\"^GSPC_MACD\"].plot(\n",
        "        title = \"GSPC Moving Average Convergence/Divergence \", label = label,\n",
        "        figsize = (20, 10), color =\"black\")\n",
        "    plt.title(\"GSPC Moving Average Convergence/Divergence\", fontdict = font)\n",
        "    rm.plot(label = \"Signal Line\", ax = ax,\n",
        "            color = \"#9a0200\", alpha = 1) \n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"MACD Values\", fontsize = 30, fontdict = font)\n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    \n",
        "    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 54)) \n",
        "    # set formatter\n",
        "    # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') +\\\n",
        "     np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax) \n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.savefig(\"GSPC MACD PLOT.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "plot_MACD(returns_data[\"^GSPC signal line\"],\"^GSPC MACD\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVHJJBCuzAQU"
      },
      "source": [
        "def computeRSI(data, time_window):\n",
        "    diff = data.diff(1).dropna()        # diff in one field(one day)\n",
        "    #this preservers dimensions off diff values\n",
        "    up_chg = 0 * diff\n",
        "    down_chg = 0 * diff\n",
        "    \n",
        "    # up change is equal to the positive difference, otherwise equal to zero\n",
        "    up_chg[diff > 0] = diff[ diff>0 ]\n",
        "    \n",
        "    # down change is equal to negative deifference, otherwise equal to zero\n",
        "    down_chg[diff < 0] = diff[ diff < 0 ]\n",
        "    \n",
        "    # check pandas documentation for ewm\n",
        "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html\n",
        "    # values are related to exponential decay\n",
        "    # we set com=time_window-1 so we get decay alpha=1/time_window\n",
        "    up_chg_avg   = up_chg.ewm(com=time_window-1 , min_periods=time_window).mean()\n",
        "    down_chg_avg = down_chg.ewm(com=time_window-1 , min_periods=time_window).mean()\n",
        "    \n",
        "    rs = abs(up_chg_avg/down_chg_avg)\n",
        "    rsi = 100 - 100/(1+rs)\n",
        "    return rsi\n",
        "\n",
        "\n",
        "def computeSO(close_data, low_data, high_data, n):\n",
        "\n",
        "  KPct = ((close_data - pd.DataFrame.rolling(low_data, n).min())/(pd.DataFrame.rolling(high_data, n).max() - pd.DataFrame.rolling(low_data, n).min()))*100\n",
        "  DPct = pd.DataFrame.rolling(KPct,3).mean()\n",
        "  return KPct, DPct\n",
        "\n",
        "def computeWRPct(close_data, low_data, high_data, n):\n",
        "    RPct = ((pd.DataFrame.rolling(high_data, n).max() - close_data)/(pd.DataFrame.rolling(high_data, n).max() - pd.DataFrame.rolling(low_data, n).min()))*-100\n",
        "    return RPct\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE7iVuNG4FQF"
      },
      "source": [
        "returns_data[\"^GSPC_14d_RSI\"] = computeRSI(returns_data[\"^GSPC Adj Close\"], time_window = 14)\n",
        "\n",
        "returns_data[\"^GSPC_14d_SO%K\"], returns_data[\"^GSPC_14d_SO%D\"]= computeSO(returns_data[\"^GSPC Adj Close\"], price_data[\"^GSPC Low\"], price_data[\"^GSPC High\"], 14)\n",
        "\n",
        "returns_data[\"^GSPC_14d_WR%\"] = computeWRPct(returns_data[\"^GSPC Adj Close\"], price_data[\"^GSPC Low\"], price_data[\"^GSPC High\"], 14)\n",
        "\n",
        "returns_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-skHWl4wWU"
      },
      "source": [
        "def plot_RSI(RSI, label):\n",
        "    ax = RSI.plot(title = \"GSPC\", label = label,\n",
        "                 figsize = (20, 10), color = \"#5079bc\")\n",
        "    plt.title(\"GSPC 14-Day Relative Strength Index\", fontdict = font)\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Relative Strength Value\", fontsize = 30, fontdict = font)\n",
        "    ax.legend(loc = \"upper left\", fontsize = 20)\n",
        "    \n",
        "    \n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    \n",
        "    \n",
        "    \n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 56)) # set formatter\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    datemin = np.datetime64(returns_data.index.values[0], 'Y')\n",
        "    datemax = np.datetime64(returns_data.index.values[-1], 'Y') + np.timedelta64(1, 'Y')\n",
        "    ax.set_xlim(datemin, datemax) \n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.axhline(0, linestyle='--', alpha=0.1, color = \"black\")\n",
        "    plt.axhline(20, linestyle='--', alpha=0.5, color = \"black\")\n",
        "    plt.axhline(30, linestyle='--', color = \"black\")\n",
        "\n",
        "    plt.axhline(70, linestyle='--', color = \"black\")\n",
        "    plt.axhline(80, linestyle='--', alpha=0.5, color = \"black\")\n",
        "    plt.axhline(100, linestyle='--', alpha=0.1, color = \"black\")\n",
        "    plt.savefig(\"GSPC Relative Strength.pdf\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_RSI(returns_data[\"^GSPC_14d_RSI\"], label = \"Relative Strength Index for ^GSPC\")\n",
        "\n",
        "# plot corresponding RSI values and significant levels\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "################\n",
        "\n",
        "def plot_SO(SO, label):\n",
        "    ax = SO.plot(y = [\"^GSPC_14d_SO%K\", \"^GSPC_14d_SO%D\"], figsize = (20, 10),\n",
        "                 color = [\"cornflowerblue\", \"orchid\"], label = label)\n",
        "    plt.title(\"GSPC Stochastic Oscillator (Momentum Measure)\", fontdict = font)\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    ax.legend(fontsize = 20,)\n",
        "    \n",
        "    \n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    \n",
        "    \n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 52)) # set formatter\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.xticks(rotation = 0)\n",
        "    plt.show()\n",
        "    plt.savefig(\"GSPC Stochastic Oscillator.pdf\")\n",
        "\n",
        "plot_SO(returns_data, label = [\"^GSPC 21-Day %K\",  \"^GSPC 21-Day %D\"])\n",
        "\n",
        "# plot corresponding RSI values and significant levels\n",
        "\n",
        "plt.show()\n",
        "\n",
        "###########################\n",
        "def plot_WPct(SO, label):\n",
        "    ax = SO.plot(y = [\"^GSPC_14d_WR%\"], figsize = (20, 10),color = [\"#5079bc\"], label = label)\n",
        "    plt.title(\"GSPC William's R% (Momentum Measure)\", fontdict = font)\n",
        "    ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "    ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "    ax.legend(fontsize = 20,)\n",
        "    \n",
        "    \n",
        "    plt.rc(\"legend\", fontsize = 30)\n",
        "    plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=20)\n",
        "    \n",
        "    \n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 52)) # set formatter\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.xticks(rotation = 0)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.savefig(\"GSPC William's R%.pdf\")\n",
        "\n",
        "plot_WPct(returns_data, label = [\"^GSPC 14-Day William's R%\"])\n",
        "\n",
        "# plot corresponding RSI values and significant levels\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6ku5qbToOq"
      },
      "source": [
        "returns_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iB-LJWenAww"
      },
      "source": [
        "\n",
        "#Ease of Movement \n",
        "def compute_EVM(ndays): \n",
        " dm = ((price_data['^GSPC High'] + price_data['^GSPC Low'])/2) - ((price_data['^GSPC High'].shift(1) + price_data['^GSPC Low'].shift(1))/2)\n",
        " br = (volume_data['^GSPC Volume'] / 100000000) / ((price_data['^GSPC High'] - price_data['^GSPC Low']))\n",
        " EVM = dm / br \n",
        " EVM_MA = pd.Series(EVM.rolling(ndays).mean(), name = 'EVM') \n",
        " returns_data[\"^GSPC_{}d_EVM\".format(ndays)] = EVM_MA  \n",
        " \n",
        "# Retrieve the AAPL data from Yahoo finance:\n",
        "\n",
        "# Compute the 14-day Ease of Movement for AAPL\n",
        "compute_EVM(14)\n",
        "\n",
        "# Plotting the Price Series chart and the Ease Of Movement below\n",
        "\n",
        "def plot_EVM(data):\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "  ax = fig.add_subplot(2, 1, 1)\n",
        "  ax.set_xticklabels([])\n",
        "  plt.plot(returns_data['^GSPC Adj Close'],lw=1, label = \"GSPC\")\n",
        "  plt.title('GSPC 14-Day Ease of Movement Plot', fontdict = font)  \n",
        "  plt.ylabel('close price')\n",
        "  plt.grid(True)\n",
        "  bx = fig.add_subplot(2, 1, 2)\n",
        "  plt.plot(data,'#5079bc',lw=0.75,linestyle='-')\n",
        "  plt.legend(loc=2,prop={'size':9}, fontsize = 20)\n",
        "  plt.grid(True)\n",
        "  plt.setp(plt.gca().get_xticklabels(), rotation=0)\n",
        "  ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "  ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "  ax.legend(fontsize = 20,)\n",
        "\n",
        "  plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=20)\n",
        "\n",
        "\n",
        "  ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 25)) # set formatter\n",
        "  ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "  plt.gcf().autofmt_xdate()\n",
        "  ax.get_yaxis().set_major_formatter(\n",
        "  matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "  bx.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "  bx.set_ylabel(\"EMV Values\", fontsize = 30, fontdict = font)\n",
        "  bx.legend(fontsize = 20,)\n",
        "\n",
        "\n",
        "\n",
        "  plt.rc(\"legend\", fontsize = 30)\n",
        "  plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=20)\n",
        "\n",
        "\n",
        "  bx.xaxis.set_major_locator(mdates.MonthLocator(interval = 56)) # set formatter\n",
        "  bx.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "  plt.gcf().autofmt_xdate()\n",
        "  plt.xticks(rotation = 0)\n",
        "\n",
        "  plt.savefig(\"GSPC Ease of Movement.pdf\")\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_EVM(returns_data[\"^GSPC_14d_EVM\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5evpEDGhgSTm"
      },
      "source": [
        "# Rate of Change code\n",
        "# Rate of Change (ROC)\n",
        "def ROC(data,n):\n",
        " N = data['^GSPC Adj Close'].diff(n)\n",
        " D = data['^GSPC Adj Close'].shift(n)\n",
        " ROC = pd.Series(N/D,name='Rate of Change')\n",
        " data = data.join(ROC)\n",
        " return data \n",
        " \n",
        "def plot_ROC(data):\n",
        "  fig = plt.figure(figsize=(20,10))\n",
        "  ax = fig.add_subplot(3, 1, 1)\n",
        "  ax.set_xticklabels([])\n",
        "  plt.plot(returns_data['^GSPC Adj Close'],lw=1, label = \"GSPC\")\n",
        "  plt.title('GPSC 5-Day Rate of Change (ROC) Plot', fontdict = font)  \n",
        "  plt.ylabel('Close Price')\n",
        "  plt.grid(True)\n",
        "  bx = fig.add_subplot(3, 1, 2)\n",
        "  plt.plot(data,'#5079bc',lw=0.75,linestyle='-',label='GSPC 5-Day Rate of Change')\n",
        "  plt.legend(loc=1,prop={'size':10}, fontsize = 20)\n",
        "  plt.grid(True)\n",
        "  plt.setp(plt.gca().get_xticklabels(), rotation=0)\n",
        "  ax.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "  ax.set_ylabel(\"Price\", fontsize = 30, fontdict = font)\n",
        "  ax.legend(fontsize = 20,)\n",
        "  \n",
        "  plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=20)\n",
        "\n",
        "  cx = fig.add_subplot(3, 1, 3)\n",
        "  plt.plot(returns_data[\"^GSPC_14d_EVM\"],'#5079bc',lw=0.75,linestyle='-',label='GSPC 14-Day EVM')\n",
        "  plt.legend(loc=1,prop={'size':10}, fontsize = 20)\n",
        "  plt.grid(True)\n",
        "  ax.xaxis.set_major_locator(mdates.MonthLocator(interval = 25)) # set formatter\n",
        "  ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "  plt.gcf().autofmt_xdate()\n",
        "  ax.get_yaxis().set_major_formatter(\n",
        "  matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "  bx.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "  bx.set_ylabel(\"ROC Vals\", fontsize = 30, fontdict = font)\n",
        "  bx.legend(fontsize = 20,)\n",
        "  cx.set_xlabel(\"Date\",  fontsize = 30, fontdict = font)\n",
        "  cx.set_ylabel(\"EVM Vals\", fontsize = 30, fontdict = font)\n",
        "  cx.legend(fontsize = 20,)\n",
        "\n",
        "\n",
        "  plt.rc(\"legend\", fontsize = 30)\n",
        "  plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
        "  plt.rc('ytick', labelsize=20)\n",
        "  cx.xaxis.set_major_locator(mdates.MonthLocator(interval = 54)) # set formatter\n",
        "  cx.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "\n",
        "  bx.xaxis.set_major_locator(mdates.MonthLocator(interval = 54)) # set formatter\n",
        "  bx.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y')) # set font and rotation for date tick labels  \n",
        "  plt.gcf().autofmt_xdate()\n",
        "  plt.xticks(rotation = 0)\n",
        "\n",
        "  plt.savefig(\"GSPC Rate of Change & Close.pdf\")\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  plt.show()\n",
        "# Compute the 5-period Rate of Change for NIFTY\n",
        "\n",
        "GSPC_5d_ROC = ROC(returns_data,5)\n",
        "returns_data[\"^GSPC_5d_ROC\"] = GSPC_5d_ROC['Rate of Change']\n",
        "\n",
        "plot_ROC(returns_data[\"^GSPC_5d_ROC\"])\n",
        "\n",
        "# Plotting the Price Series chart and the Ease Of Movement below\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znj7FLc0k85I"
      },
      "source": [
        "def compute_ForceIndex(n): \n",
        "    FI = pd.Series(returns_data['^GSPC Adj Close'].diff(n) * volume_data['^GSPC Volume'], name = 'ForceIndex')\n",
        "    returns_data[\"^GSPC_{}d_FI\".format(n)] = FI \n",
        "\n",
        "# Compute the Force Index\n",
        "compute_ForceIndex(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgm59PL5Clhc"
      },
      "source": [
        "#Moving Average (5, 10, 21, 63, 126, 252)\n",
        "#Exponential Moving Average (5, 10, 21, 63, 126, 252)\n",
        "#Rolling Std and Bollinger Bands (5, 10, 21, 63, 126, 252)\n",
        "#Relative Strength Index (21)\n",
        "#Stochastic Oscillator(252 days)\n",
        "#William's R% (252 days)\n",
        "#Rate of Change (5 days)\n",
        "#Force Index (5 days)\n",
        "#Ease of Movement (EVM)\n",
        "#OSCP\n",
        "  #Moving Average Convergence Divergence (12-26 day)\n",
        "#returns_data = returns_data.iloc[252:, :]\n",
        "\n",
        "#returns_dat\n",
        "\n",
        "returns_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_WiqoWPGx_R"
      },
      "source": [
        "tickers = [\"^GSPC\", \"^DJI\", \"^NYA\", \"^VIX\",\"^IXIC\",\"^GDAXI\",\n",
        "           \"^FCHI\", \"^HSI\", \"^N225\", \"^RUT\"]\n",
        "\n",
        "for ticker in tickers[0:5]:\n",
        "  returns_data[\"{}_DailyReturn_t1\".format(ticker)] = np.nan\n",
        "  returns_data[\"{}_DailyReturn_t2\".format(ticker)] = np.nan\n",
        "  returns_data[\"{}_DailyReturn_t3\".format(ticker)] = np.nan\n",
        "\n",
        "for ticker in tickers[5:]:\n",
        "  returns_data[\"{}_DailyReturn_t\".format(ticker)] = np.nan\n",
        "  returns_data[\"{}_DailyReturn_t1\".format(ticker)] = np.nan\n",
        "  returns_data[\"{}_DailyReturn_t2\".format(ticker)] = np.nan   \n",
        "\n",
        "\n",
        "for ticker in tickers[0:5]:\n",
        "  for i in range(0, len(returns_data)):\n",
        "    returns_data[\"{}_DailyReturn_t1\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i-1]\n",
        "    returns_data[\"{}_DailyReturn_t2\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i-2]\n",
        "    returns_data[\"{}_DailyReturn_t3\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i-3]    \n",
        "\n",
        "for ticker in tickers[5:]:\n",
        "  for i in range(0, len(returns_data)):   \n",
        "    returns_data[\"{}_DailyReturn_t\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i]\n",
        "    returns_data[\"{}_DailyReturn_t1\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i-1]\n",
        "    returns_data[\"{}_DailyReturn_t2\".format(ticker)].iloc[i] =\\\n",
        "    returns_data[\"{} Daily Return\".format(ticker)].iloc[i-2]     \n",
        "\n",
        "returns_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOwHlbdkMHFi"
      },
      "source": [
        "def get_RMedian(values, windows):\n",
        "  for window in windows:\n",
        "    returns_data[\"^GSPC_Returns_{}d_RMedian\".format(str(window))] = pd.DataFrame.rolling(\n",
        "        values, window).mean() #rolling mean\n",
        "get_RMedian(returns_data[\"^GSPC Daily Return\"], [21])\n",
        "\n",
        "returns_data[\"^GSPC Return Direction\"] = 0\n",
        "returns_data.loc[\n",
        "                 returns_data[\"^GSPC Daily Return\"] >= 0, \n",
        "                 \"^GSPC Return Direction\"] = 1\n",
        "returns_data[[\"^GSPC Daily Return\", \"^GSPC Return Direction\"]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itpJhZm-ruh-"
      },
      "source": [
        "returns_data.isna().sum()\n",
        "#raw_data = returns_data.iloc[:, :20]\n",
        "#returns_data = returns_data.iloc[:,20:]\n",
        "unprocessed_data = returns_data.iloc[:, :30]\n",
        "preprocessed_data = returns_data.iloc[:, 30:]\n",
        "unprocessed_data = unprocessed_data.dropna()\n",
        "preprocessed_data =  preprocessed_data.dropna()\n",
        "\n",
        "preprocessed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ZNROths2lE"
      },
      "source": [
        "final_data = preprocessed_data.copy()\n",
        "#final_data = final_data.reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzEoellLK3KM"
      },
      "source": [
        "final_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ_71rWkDPgD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32bviXYsNqnH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aWgcRhdov1u"
      },
      "source": [
        "tmp = pd.DataFrame()\n",
        "tmp =tmp.dropna()\n",
        "tmp[\"Date\"] = returns_data.index \n",
        "tmp[\"^GSPC Adj Close\"] = returns_data[\"^GSPC Adj Close\"].values\n",
        "data_FT = tmp[['Date', '^GSPC Adj Close']]\n",
        "\n",
        "close_fft = np.fft.fft(np.asarray(data_FT['^GSPC Adj Close'].tolist()))\n",
        "fft_df = pd.DataFrame({'fft':close_fft})\n",
        "fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
        "fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
        "plt.figure(figsize=(20, 10), dpi=100)\n",
        "fft_list = np.asarray(fft_df['fft'].tolist())\n",
        "for num_ in [3, 6, 9, 100]:\n",
        "    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
        "    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))\n",
        "plt.plot(data_FT['^GSPC Adj Close'],  label=\"GSPC\")\n",
        "plt.xlabel('Days', fontsize = 30)\n",
        "plt.ylabel('Price', fontsize = 30)\n",
        "plt.title('GSPC Closing Prices & Fourier Transforms', fontdict = font)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn55JPIKUMJR"
      },
      "source": [
        "from collections import deque\n",
        "items = deque(np.asarray(fft_df['absolute'].tolist()))\n",
        "items.rotate(int(np.floor(len(fft_df)/2)))\n",
        "plt.figure(figsize=(10, 7), dpi=80)\n",
        "plt.stem(items)\n",
        "plt.title('Figure 4: Components of Fourier transforms')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzZVcskzUlKX"
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from pandas import DataFrame\n",
        "from pandas import datetime\n",
        "\n",
        "series = data_FT['^GSPC Adj Close']\n",
        "model = ARIMA(series, order=(10, 1, 2))\n",
        "model_fit = model.fit(disp=0)\n",
        "print(model_fit.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6llBdMe9UX-H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvQvH4G9BOrE"
      },
      "source": [
        "Xseries = series.values\n",
        "size = int(len(Xseries) * 0.66)\n",
        "train, test = Xseries[0:size], Xseries[size:len(X)]\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for t in range(len(test)):\n",
        "    model = ARIMA(history, order=(10,1,2))\n",
        "    model_fit = model.fit(disp=0)\n",
        "    output = model_fit.forecast()\n",
        "    yhat = output[0]\n",
        "    predictions.append(yhat)\n",
        "    obs = test[t]\n",
        "    history.append(obs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgAVkiN9mChZ"
      },
      "source": [
        "Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51_Qe_zxaF3P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow8nfGxwTHSC"
      },
      "source": [
        "# Model Implementations and Metrics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNgCAR9Tks7F"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pojVONXTh6T7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "X,y = final_data.iloc[:,:-1],final_data.iloc[:,-1:] \n",
        "tscv = TimeSeriesSplit()\n",
        "print(tscv)\n",
        "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
        "for train_index, test_index in tscv.split(X):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "my_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "X_train_preprocessed = pd.DataFrame(my_scaler.fit_transform(X_train))\n",
        "X_test_preprocessed = pd.DataFrame(my_scaler.transform(X_test))\n",
        " \n",
        "X_train_preprocessed.columns = X_train.columns\n",
        "X_test_preprocessed.columns = X_test.columns\n",
        "# correlation_dataset = X_train_preprocessed.append) \n",
        "X_train_preprocessed[\"^GSPC Return Direction\"] = y_train.iloc[:,0].values\n",
        "\n",
        "\n",
        "\n",
        "# pd.set_option('display.max_rows', X_train_preprocessed.shape[0]+1)\n",
        "\n",
        "correlations = pd.DataFrame(X_train_preprocessed.corr()[\"^GSPC Return Direction\"][:68])\n",
        "\n",
        "del X_train_preprocessed[\"^GSPC Return Direction\"]\n",
        "\n",
        "relevant_features = list(correlations[abs(correlations[\"^GSPC Return Direction\"])>0.05].index)\n",
        "\n",
        "X_train_preprocessed_engineering = X_train_preprocessed[relevant_features] \n",
        "\n",
        "X_test_preprocessed_engineering = X_test_preprocessed[relevant_features]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGGpDRMhLgZ_"
      },
      "source": [
        "rbfclf = sk.svm.SVC(kernel = \"rbf\", max_iter = 5000)\n",
        "\n",
        "rbfclf.fit(X_train_preprocessed_engineering, y_train)\n",
        "\n",
        "rbfprediction = rbfclf.predict(X_test_preprocessed_engineering)\n",
        "\n",
        "\n",
        "rbfaccuracy = rbfclf.score(X_test_preprocessed_engineering, y_test)\n",
        "rbf_f1_score = sk.metrics.f1_score(y_test, rbfprediction)\n",
        "rbf_baccuracy = sk.metrics.balanced_accuracy_score(y_test, rbfprediction)\n",
        "rbf_precision = sk.metrics.precision_score(y_test ,rbfprediction)\n",
        "rbf_recall = sk.metrics.recall_score(y_test, rbfprediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SMzd3HOY5V0"
      },
      "source": [
        "rbf_f1_score, rbf_precision, rbfaccuracy, rbf_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0gnopU347LJ"
      },
      "source": [
        "\n",
        "def input_fn(features, labels, batch_size=252):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    # Shuffle and repeat if you are in training mode.'\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "my_feature_columns = []\n",
        "for key in X_train_preprocessed_engineering.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)\n",
        "\n",
        "    \n",
        "BRFClassifier = tf.estimator.BoostedTreesClassifier(my_feature_columns, n_batches_per_layer = 1,  \n",
        "  n_classes = 2, learning_rate = 0.115, n_trees = 80, max_depth = 8)\n",
        "BRFClassifier.train(input_fn = lambda: input_fn(X_train_preprocessed_engineering, y_train), steps = 5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3LzJlsiGPvz"
      },
      "source": [
        "BRFeval_result = BRFClassifier.evaluate(input_fn = lambda: input_fn(X_test_preprocessed_engineering,\n",
        "                                                y_test))\n",
        "print(\"\\nTest Set Accuracy: {}.\\n\".format(BRFeval_result))\n",
        "\n",
        "y_pred = BRFClassifier.predict(X_test_preprocessed_engineering)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44mZmdbxGufG"
      },
      "source": [
        "tmp = final_data.rename(columns={x: str(y) for x,y in zip(final_data.columns,range(0,len(final_data.columns)))})\n",
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "X,y = tmp.iloc[:,:-1],tmp.iloc[:,-1:] \n",
        "tscv = TimeSeriesSplit()\n",
        "print(tscv)\n",
        "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
        "for train_index, test_index in tscv.split(X):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "my_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "X_train_preprocessed = pd.DataFrame(my_scaler.fit_transform(X_train))\n",
        "X_test_preprocessed = pd.DataFrame(my_scaler.transform(X_test))\n",
        " \n",
        "X_train_preprocessed.columns = X_train.columns\n",
        "X_test_preprocessed.columns = X_test.columns\n",
        "# correlation_dataset = X_train_preprocessed.append) \n",
        "X_train_preprocessed[\"^GSPC Return Direction\"] = y_train.iloc[:,0].values\n",
        "\n",
        "\n",
        "\n",
        "# pd.set_option('display.max_rows', X_train_preprocessed.shape[0]+1)\n",
        "\n",
        "correlations = pd.DataFrame(X_train_preprocessed.corr()[\"^GSPC Return Direction\"][:68])\n",
        "\n",
        "del X_train_preprocessed[\"^GSPC Return Direction\"]\n",
        "\n",
        "relevant_features = list(correlations[abs(correlations[\"^GSPC Return Direction\"])>0.05].index)\n",
        "\n",
        "X_train_preprocessed_engineering = X_train_preprocessed[relevant_features] \n",
        "\n",
        "X_test_preprocessed_engineering = X_test_preprocessed[relevant_features]\n",
        "\n",
        "X_train_preprocessed_engineering.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMbQI8gPfEfV"
      },
      "source": [
        "def input_fn(features, labels, batch_size=252):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    # Shuffle and repeat if you are in training mode.'\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "my_feature_columns = []\n",
        "for key in X_train_preprocessed_engineering.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)\n",
        "\n",
        "result = []\n",
        "DNNClassifier = tf.estimator.DNNClassifier(\n",
        "    hidden_units = [5,10], n_classes = 2, feature_columns = my_feature_columns,\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.03))\n",
        "\n",
        "DNNClassifier.train(input_fn = lambda: input_fn(X_train_preprocessed_engineering, y_train), steps = 10000)\n",
        "DNNeval_result = DNNClassifier.evaluate(input_fn = lambda: input_fn(X_test_preprocessed_engineering, y_test))\n",
        "result.append(DNNeval_result[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It2fNaBuitO7"
      },
      "source": [
        "# h =[]\n",
        "# for i in range(0,len(result),60):\n",
        "#   avgacc = sum(result[i:i+60])/60\n",
        "#   h.append(avgacc)\n",
        "# print(sorted(h))\n",
        "# print(h)\n",
        "\n",
        "# [[5,5], [5,10], [6,4], [10,10]]\n",
        "\n",
        "result\n",
        "\n",
        "print(\"DNNClassifier([5,10]) Accuracy: {}%\".format(round(result[0]*100)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3iM5R88P13k"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# X,y = final_data.iloc[:,:-1].values, final_data.iloc[:,-1:].values \n",
        "# tscv = TimeSeriesSplit()\n",
        "# print(tscv)\n",
        "# TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
        "# for train_index, test_index in tscv.split(X):\n",
        "#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "#   X_train, X_test = X[train_index], X[test_index]\n",
        "#   y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "tmp = final_data.rename(columns={x: str(y) for x,y in zip(final_data.columns,range(0,len(final_data.columns)))})\n",
        "import numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "X,y = tmp.iloc[:,:-1],tmp.iloc[:,-1:] \n",
        "tscv = TimeSeriesSplit()\n",
        "print(tscv)\n",
        "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
        "for train_index, test_index in tscv.split(X):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "my_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "X_train_preprocessed = pd.DataFrame(my_scaler.fit_transform(X_train))\n",
        "X_test_preprocessed = pd.DataFrame(my_scaler.transform(X_test))\n",
        "\n",
        "X_train_preprocessed.columns = X_train.columns\n",
        "X_test_preprocessed.columns = X_test.columns\n",
        "# correlation_dataset = X_train_preprocessed.append) \n",
        "X_train_preprocessed[\"^GSPC Return Direction\"] = y_train.iloc[:,0].values\n",
        "\n",
        "\n",
        "\n",
        "# pd.set_option('display.max_rows', X_train_preprocessed.shape[0]+1)\n",
        "\n",
        "# correlations = pd.DataFrame(X_train_preprocessed.corr()[\"^GSPC Return Direction\"][:68])\n",
        "\n",
        "# del X_train_preprocessed[\"^GSPC Return Direction\"]\n",
        "\n",
        "relevant_features = list(correlations[abs(correlations[\"^GSPC Return Direction\"])>0.05].index)\n",
        "\n",
        "X_train_preprocessed_engineering = X_train_preprocessed[relevant_features] \n",
        "\n",
        "X_test_preprocessed_engineering = X_test_preprocessed[relevant_features]\n",
        "\n",
        "X_test_preprocessed_engineering, X_train_preprocessed_engineering, y_test, y_train = X_test_preprocessed_engineering.values, X_train_preprocessed_engineering.values, y_test.values, y_train.values\n",
        "\n",
        "\n",
        "X_train = X_train_preprocessed_engineering.reshape((X_train_preprocessed_engineering.shape[0], 1, X_train_preprocessed_engineering.shape[1]))\n",
        "X_test = X_test_preprocessed_engineering.reshape((X_test_preprocessed_engineering.shape[0], 1, X_test_preprocessed_engineering.shape[1]))\n",
        "print(X_train_preprocessed_engineering.shape, y_train.shape, X_test_preprocessed_engineering.shape, y_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX5gqAYUqsrT"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(units = 10, activation = \"relu\", input_shape = [13]),\n",
        "                           tf.keras.layers.Dropout(rate=0.2),\n",
        "                           tf.keras.layers.Dense(10, activation='relu'),\n",
        "                           tf.keras.layers.Dropout(rate=0.2),\n",
        "                           tf.keras.layers.Dense(5, activation='relu'),\n",
        "                           tf.keras.layers.Dropout(rate=0.2), \n",
        "                          #  tf.keras.layers.BatchNormalization(),\n",
        "                           tf.keras.layers.Dense(2, activation = \"softmax\")\n",
        "                           ])\n",
        "\n",
        "opt = tf.keras.optimizers.Adagrad(learning_rate = .01)\n",
        "model.compile(optimizer=opt, loss='mae', metrics = [\"acc\"])\n",
        "history = model.fit(X_train_preprocessed_engineering, y_train, \n",
        "          batch_size = 10, epochs = 50, shuffle = False, validation_data = (X_test_preprocessed_engineering, y_test), verbose = 0)\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', \"val_loss\"]].plot()\n",
        "history_df.loc[:, [\"acc\", \"val_acc\"]].plot()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38AZO11VJanm"
      },
      "source": [
        "history_df.iloc[49,]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4fiwDYJCj0T"
      },
      "source": [
        "\n",
        "\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units = 10, input_shape = [1,13],\n",
        "                                activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dense(units = 5, activation = \"relu\"))\n",
        "model.add(tf.keras.layers.Dense(units = 2, activation=\"softmax\"))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.1)\n",
        "model.compile(optimizer = opt, \n",
        "              loss = \"mse\")\n",
        "#out_batch = NBatchLogger(display=1000)\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size = 21, epochs = 100, shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S5JhhrsMHfx"
      },
      "source": [
        "pd.DataFrame(X_train_preprocessed_engineering).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfQxwowNUF8c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units = 10, return_sequences = True,recurrent_activation=\"tanh\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(units = 10, return_sequences = True, recurrent_activation= \"tanh\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 2, activation = \"softmax\"))\n",
        "opt = tf.keras.optimizers.Adagrad(learning_rate = 0.01)\n",
        "model.compile(optimizer = opt, loss = 'mse', metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(X_train_preprocessed_engineering , y_train, epochs = 50, batch_size = 20, shuffle = True)\n",
        "\n",
        "predicted_stock_price = model.predict(X_test_preprocessed_engineering)\n",
        "\n",
        "\n",
        "m = tf.keras.metrics.Accuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60MZOzndHW4"
      },
      "source": [
        "m.update_state(y_test, predicted_stock_price)\n",
        "predicted_stock_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiCeBFQmujOn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l1_l2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "\n",
        "class Double_Tanh(Activation):\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Double_Tanh, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'double_tanh'\n",
        "\n",
        "def double_tanh(x):\n",
        "    return (K.tanh(x) * 2)\n",
        "\n",
        "get_custom_objects().update({'double_tanh':Double_Tanh(double_tanh)})\n",
        "\n",
        "\n",
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(25, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "model.add(Activation(double_tanh))\n",
        "model.add(tf.keras.layers.Dense(units = 1, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer= opt,\n",
        "metrics=[\"mse\", \"mae\", \"accuracy\"])\n",
        "# fit network\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test),\n",
        "                    verbose=2, shuffle=False)\n",
        "# plot history\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ARlCFES_W8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=3, return_sequences = True,\n",
        "               input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=2, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=3, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=2, return_sequences = False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units =1))\n",
        "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\", metrics = [\"accuracy\",f1_m,precision_m, recall_m])\n",
        "model.fit(X_train, y_train, epochs = 50, batch_size = 32, verbose=2)\n",
        "\n",
        "\n",
        "predicted_stock_price = model.predict(X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9oVp6LESldZ"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(X_train, y_train, validation_split=0.3, epochs=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUsEuOX7UHD4"
      },
      "source": [
        "#write up start with exploratory data analysis and methods \n",
        "#shift data for your own stocks (consu;t 6)\n",
        "#split data\n",
        "#train random forest, neural networks, svm, and arima\n",
        "#table results\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}